# Importer le patch en premier pour corriger face_recognition_models
import face_recognition_patch

import face_recognition
import os
import cv2
import numpy as np
from typing import List, Dict, Tuple, Optional
from sqlalchemy.orm import Session
from models import User, Photo, FaceMatch
import uuid
import io
from PIL import Image
from photo_optimizer import PhotoOptimizer
from datetime import datetime, timedelta, timezone

class FaceRecognizer:
    def __init__(self, tolerance=0.7):
        import os as _os
        # Permettre d'ajuster par variable d'environnement si besoin
        try:
            tol_env = _os.getenv("FACE_RECOGNITION_TOLERANCE")
            if tol_env is not None:
                tolerance = float(tol_env)
        except Exception:
            pass
        self.tolerance = tolerance
        # Cache global des encodages utilisateurs (user_id -> embedding)
        self.user_encodings: Dict[int, np.ndarray] = {}
        # Cache par √©v√©nement (event_id -> {user_id -> embedding})
        self.event_user_encodings: Dict[int, Dict[int, np.ndarray]] = {}

    def load_user_encoding(self, user: User) -> Optional[np.ndarray]:
        """Charge l'encodage facial d'un utilisateur depuis son selfie (avec EXIF + robustesse)."""
        if not user.selfie_data:
            return None
        try:
            # Charger via PIL pour corriger l'orientation EXIF et normaliser en RGB
            pil_img = Image.open(io.BytesIO(bytes(user.selfie_data)))
            from PIL import ImageOps as _ImageOps
            pil_img = _ImageOps.exif_transpose(pil_img)
            if pil_img.mode not in ("RGB", "L"):
                pil_img = pil_img.convert("RGB")
            np_img = np.array(pil_img)
            encodings = face_recognition.face_encodings(np_img)
            if encodings:
                return encodings[0]
        except Exception as e:
            print(f"Erreur lors du chargement de l'encodage pour {getattr(user, 'username', user.id)}: {e}")
        return None

    def _detect_faces_multipass(self, np_img: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """D√©tection robuste multi-pass avec HOG (upsample 0‚Üí2) + fallback Haar, d√©doublonn√©e.

        Retourne des box (top, right, bottom, left) dans l'espace de l'image d'origine.
        """
        try:
            img_h, img_w = np_img.shape[0], np_img.shape[1]

            # D√©tection principale HOG √† diff√©rentes √©chelles d'upsampling
            faces: List[Tuple[int, int, int, int]] = []
            try:
                faces += face_recognition.face_locations(np_img, model="hog", number_of_times_to_upsample=0) or []
            except Exception:
                pass
            if len(faces) < 2:
                try:
                    faces2 = face_recognition.face_locations(np_img, model="hog", number_of_times_to_upsample=1) or []
                    faces += faces2
                except Exception:
                    pass
            if len(faces) < 2:
                try:
                    faces3 = face_recognition.face_locations(np_img, model="hog", number_of_times_to_upsample=2) or []
                    faces += faces3
                except Exception:
                    pass

            # Fallback Haar si rien ou tr√®s peu d√©tect√©
            if len(faces) == 0:
                try:
                    gray = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)
                    cascades = [
                        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml',
                        cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml',
                        cv2.data.haarcascades + 'haarcascade_profileface.xml',
                    ]
                    rects_all = []
                    for cpath in cascades:
                        fc = cv2.CascadeClassifier(cpath)
                        if fc.empty():
                            continue
                        rects = fc.detectMultiScale(gray, scaleFactor=1.08, minNeighbors=5, minSize=(36, 36))
                        rects_all.extend(rects)
                    faces = [(int(y), int(x+w), int(y+h), int(x)) for (x, y, w, h) in rects_all]
                except Exception:
                    faces = []

            # D√©duplication par IoU
            def _iou(a, b):
                (t1, r1, b1, l1) = a
                (t2, r2, b2, l2) = b
                xA = max(l1, l2)
                yA = max(t1, t2)
                xB = min(r1, r2)
                yB = min(b1, b2)
                interW = max(0, xB - xA)
                interH = max(0, yB - yA)
                inter = interW * interH
                area1 = max(0, (r1 - l1)) * max(0, (b1 - t1))
                area2 = max(0, (r2 - l2)) * max(0, (b2 - t2))
                union = area1 + area2 - inter if (area1 + area2 - inter) > 0 else 1
                return inter / union

            unique: List[Tuple[int, int, int, int]] = []
            for f in faces:
                top, right, bottom, left = f
                if (right - left) <= 0 or (bottom - top) <= 0:
                    continue
                if not unique:
                    unique.append(f)
                    continue
                if all(_iou(f, u) < 0.4 for u in unique):
                    unique.append(f)
            return unique
        except Exception as _e:
            return []

    def detect_faces(self, image_data: bytes) -> List[Tuple[int, int, int, int]]:
        """D√©tecte les visages dans une image et retourne leurs positions"""
        try:
            # Convertir les donn√©es binaires en image (PIL) et r√©duire pour limiter la RAM
            image_bytes = io.BytesIO(image_data)
            pil_img = Image.open(image_bytes)
            from PIL import ImageOps as _ImageOps
            pil_img = _ImageOps.exif_transpose(pil_img)
            if pil_img.mode not in ("RGB", "L"):
                pil_img = pil_img.convert("RGB")

            # Downscale agressif pour √©viter l'OOM sur Render free (max 1280px)
            max_dim = 1280
            w, h = pil_img.size
            scale = min(1.0, max_dim / float(max(w, h)))
            if scale < 1.0:
                pil_img = pil_img.resize((int(w * scale), int(h * scale)), Image.Resampling.LANCZOS)

            # Convertir en numpy array pour face_recognition
            np_img = np.array(pil_img)

            # D√©tecter les visages (mod√®le HOG, plus l√©ger que CNN). Si aucun visage,
            # tenter un second passage avec upsample=1 (plus sensible) mais encore l√©ger.
            face_locations = face_recognition.face_locations(np_img, model="hog", number_of_times_to_upsample=0)
            if not face_locations:
                face_locations = face_recognition.face_locations(np_img, model="hog", number_of_times_to_upsample=1)

            # Fallback OpenCV Haar cascade si rien d√©tect√© (environnement contraint)
            if not face_locations:
                try:
                    gray = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)
                    cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                    face_cascade = cv2.CascadeClassifier(cascade_path)
                    rects = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))
                    # Convertir (x, y, w, h) -> (top, right, bottom, left)
                    face_locations = [(int(y), int(x+w), int(y+h), int(x)) for (x, y, w, h) in rects]
                except Exception as _e:
                    pass
            
            return face_locations
            
        except Exception as e:
            print(f"Erreur lors de la d√©tection de visages: {e}")
            return []

    def get_all_user_encodings(self, db: Session) -> Dict[int, np.ndarray]:
        """R√©cup√®re les encodages de tous les utilisateurs (avec cache en m√©moire)."""
        users = db.query(User).filter(User.selfie_data.isnot(None)).all()
        for user in users:
            if user.id not in self.user_encodings:
                encoding = self.load_user_encoding(user)
                if encoding is not None:
                    self.user_encodings[user.id] = encoding
        return dict(self.user_encodings)

    def get_user_encodings_for_event(self, db: Session, event_id: int) -> Dict[int, np.ndarray]:
        """Encodages des utilisateurs d'un √©v√©nement (cache par event_id)."""
        if event_id in self.event_user_encodings:
            return self.event_user_encodings[event_id]
        from models import UserEvent
        user_events = db.query(UserEvent).filter(UserEvent.event_id == event_id).all()
        user_ids = [ue.user_id for ue in user_events]
        users_with_selfies = db.query(User).filter(
            User.id.in_(user_ids),
            User.selfie_data.isnot(None)
        ).all()
        encodings: Dict[int, np.ndarray] = {}
        for user in users_with_selfies:
            enc = self.user_encodings.get(user.id)
            if enc is None:
                enc = self.load_user_encoding(user)
                if enc is not None:
                    self.user_encodings[user.id] = enc
            if enc is not None:
                encodings[user.id] = enc
        self.event_user_encodings[event_id] = encodings
        return encodings

    def process_photo(self, photo_data: bytes, db: Session) -> List[Dict]:
        """Traite une photo et retourne les correspondances trouv√©es.

        Accepte soit des donn√©es binaires d'image, soit un chemin de fichier (str).
        """
        if not photo_data:
            return []

        try:
            # Charger l'image (chemin/bytes) via PIL pour normaliser EXIF + RGB
            if isinstance(photo_data, str) and os.path.exists(photo_data):
                with open(photo_data, 'rb') as f:
                    raw_bytes = f.read()
            else:
                raw_bytes = bytes(photo_data)

            pil_img = Image.open(io.BytesIO(raw_bytes))
            from PIL import ImageOps as _ImageOps
            pil_img = _ImageOps.exif_transpose(pil_img)
            if pil_img.mode not in ("RGB", "L"):
                pil_img = pil_img.convert("RGB")
            np_img = np.array(pil_img)

            # D√©tection robuste
            face_locations = self._detect_faces_multipass(np_img)
            if not face_locations:
                return []
            # Encodage des visages d√©tect√©s
            face_encodings = face_recognition.face_encodings(np_img, face_locations)
            if not face_encodings:
                return []

            # Encodages utilisateurs (avec cache)
            user_encodings = self.get_all_user_encodings(db)
            if not user_encodings:
                return []

            user_ids = list(user_encodings.keys())
            user_matrix = np.array([user_encodings[uid] for uid in user_ids])

            # Calcul vectoris√© des distances et agr√©gation par utilisateur (max score)
            best_by_user: Dict[int, int] = {}
            for enc in face_encodings:
                try:
                    dists = face_recognition.face_distance(user_matrix, enc)
                except Exception:
                    # Fallback non vectoris√©
                    dists = np.array([face_recognition.face_distance([u], enc)[0] for u in user_matrix])
                for idx, dist in enumerate(dists):
                    if dist <= self.tolerance:
                        uid = user_ids[idx]
                        score = max(0, int((1 - float(dist)) * 100))
                        if (uid not in best_by_user) or (score > best_by_user[uid]):
                            best_by_user[uid] = score

            matches = [{
                'user_id': uid,
                'confidence_score': score,
                'distance': 1 - (score / 100.0)
            } for uid, score in best_by_user.items()]

            return matches
            
        except Exception as e:
            print(f"Erreur lors du traitement de la photo: {e}")
            return []

    def process_and_save_photo(self, photo_path: str, original_filename: str, 
                             photographer_id: Optional[int], db: Session) -> Photo:
        """Traite une photo, sauvegarde les correspondances et retourne l'objet Photo"""
        
        # Lire le fichier et le convertir en donn√©es binaires
        with open(photo_path, 'rb') as f:
            original_data = f.read()
        
        # Optimiser l'image avant sauvegarde
        optimization_result = PhotoOptimizer.optimize_image(
            image_data=original_data,
            photo_type='uploaded'
        )
        
        # G√©n√©rer un nom de fichier unique (toujours JPG apr√®s optimisation)
        unique_filename = f"{uuid.uuid4()}.jpg"
        
        # Trouver l'√©v√©nement associ√© au photographe
        event_id = None
        if photographer_id:
            from models import Event
            event = db.query(Event).filter(Event.photographer_id == photographer_id).first()
            if event:
                event_id = event.id
                print(f"‚úÖ √âv√©nement trouv√© pour photographe {photographer_id}: {event.name} (ID: {event_id})")
            else:
                print(f"‚ö†Ô∏è  Aucun √©v√©nement trouv√© pour photographe {photographer_id}")
        else:
            print("‚ö†Ô∏è  Aucun photographe_id fourni")
        
        # Cr√©er l'enregistrement Photo avec les donn√©es optimis√©es
        photo = Photo(
            filename=unique_filename,
            original_filename=original_filename,
            photo_data=optimization_result['compressed_data'],
            content_type=optimization_result['content_type'],
            photo_type="uploaded",
            photographer_id=photographer_id,
            event_id=event_id,
            original_size=optimization_result['original_size'],
            compressed_size=optimization_result['compressed_size'],
            compression_ratio=optimization_result['compression_ratio'],
            quality_level=optimization_result['quality_level'],
            retention_days=optimization_result['retention_days'],
            expires_at=optimization_result['expires_at']
        )
        print(f"üì∏ Photo cr√©√©e: {original_filename} -> Event ID: {event_id}")
        db.add(photo)
        db.commit()
        db.refresh(photo)
        
        # Traiter la reconnaissance faciale avec les donn√©es ORIGINALES (meilleure d√©tection)
        matches = self.process_photo(original_data, db)
        
        # Sauvegarder les correspondances (robuste)
        for match in matches:
            try:
                face_match = FaceMatch(
                    photo_id=photo.id,
                    user_id=match['user_id'],
                    confidence_score=match['confidence_score']
                )
                db.add(face_match)
            except Exception:
                try:
                    db.rollback()
                except Exception:
                    pass
                try:
                    db.add(FaceMatch(photo_id=photo.id, user_id=match['user_id'], confidence_score=match['confidence_score']))
                except Exception:
                    pass
        # Nettoyage: ne conserver que les correspondances calcul√©es pour cette photo
        try:
            matched_user_ids = {m['user_id'] for m in matches} if matches else set()
            from sqlalchemy import not_ as _not
            if matched_user_ids:
                db.query(FaceMatch).filter(
                    FaceMatch.photo_id == photo.id,
                    _not(FaceMatch.user_id.in_(list(matched_user_ids)))
                ).delete(synchronize_session=False)
            else:
                db.query(FaceMatch).filter(FaceMatch.photo_id == photo.id).delete(synchronize_session=False)
        except Exception:
            try:
                db.rollback()
            except Exception:
                pass
        
        # NOUVEAU: Si associ√©e √† un √©v√©nement, r√©initialiser la date d'expiration 
        # de TOUTES les photos de cet √©v√©nement pour qu'elles expirent en m√™me temps
        if event_id:
            new_expiration = datetime.now(timezone.utc) + timedelta(days=30)
            
            # Mettre √† jour toutes les photos de l'√©v√©nement
            db.query(Photo).filter(
                Photo.event_id == event_id,
                Photo.expires_at.isnot(None)
            ).update({
                Photo.expires_at: new_expiration
            }, synchronize_session=False)
            print(f"üîÑ Toutes les photos de l'√©v√©nement {event_id} ont √©t√© r√©initialis√©es √† expirer le {new_expiration}")
        
        # Un seul commit final
        db.commit()
        return photo

    def process_and_save_photo_for_event(self, photo_path: str, original_filename: str, 
                                       photographer_id: int, event_id: int, db: Session) -> Photo:
        """Traite une photo pour un √©v√©nement sp√©cifique, sauvegarde les correspondances et retourne l'objet Photo"""
        
        # Lire le fichier et le convertir en donn√©es binaires
        with open(photo_path, 'rb') as f:
            original_data = f.read()
        
        # Optimiser l'image avant sauvegarde
        optimization_result = PhotoOptimizer.optimize_image(
            image_data=original_data,
            photo_type='uploaded'
        )
        
        # G√©n√©rer un nom de fichier unique (toujours JPG apr√®s optimisation)
        unique_filename = f"{uuid.uuid4()}.jpg"
        
        # Cr√©er l'enregistrement Photo avec les donn√©es optimis√©es
        photo = Photo(
            filename=unique_filename,
            original_filename=original_filename,
            photo_data=optimization_result['compressed_data'],
            content_type=optimization_result['content_type'],
            photo_type="uploaded",
            photographer_id=photographer_id,
            event_id=event_id,
            original_size=optimization_result['original_size'],
            compressed_size=optimization_result['compressed_size'],
            compression_ratio=optimization_result['compression_ratio'],
            quality_level=optimization_result['quality_level'],
            retention_days=optimization_result['retention_days'],
            expires_at=optimization_result['expires_at']
        )
        print(f"üì∏ Photo cr√©√©e pour √©v√©nement {event_id}: {original_filename}")
        db.add(photo)
        db.commit()
        db.refresh(photo)
        
        # Traiter la reconnaissance faciale pour cet √©v√©nement sp√©cifique AVEC les donn√©es ORIGINALES
        matches = self.process_photo_for_event(original_data, event_id, db)
        
        # Sauvegarder les correspondances
        for match in matches:
            face_match = FaceMatch(
                photo_id=photo.id,
                user_id=match['user_id'],
                confidence_score=match['confidence_score']
            )
            db.add(face_match)
        
        # NOUVEAU: R√©initialiser la date d'expiration de TOUTES les photos de cet √©v√©nement
        # pour qu'elles expirent toutes en m√™me temps (1 mois √† partir de maintenant)
        new_expiration = datetime.utcnow() + timedelta(days=30)
        
        # Mettre √† jour toutes les photos de l'√©v√©nement
        db.query(Photo).filter(
            Photo.event_id == event_id,
            Photo.expires_at.isnot(None)
        ).update({
            Photo.expires_at: new_expiration
        }, synchronize_session=False)
        
        # Un seul commit final pour toutes les op√©rations
        db.commit()
        print(f"üîÑ Toutes les photos de l'√©v√©nement {event_id} ont √©t√© r√©initialis√©es √† expirer le {new_expiration}")
        return photo

    def process_photo_for_event(self, photo_data: bytes, event_id: int, db: Session) -> List[Dict]:
        """Traite une photo et retourne les correspondances trouv√©es pour un √©v√©nement sp√©cifique.

        Accepte soit des donn√©es binaires d'image, soit un chemin de fichier (str).
        """
        if not photo_data:
            return []

        try:
            # Charger l'image (chemin/bytes) via PIL pour normaliser EXIF + RGB
            if isinstance(photo_data, str) and os.path.exists(photo_data):
                with open(photo_data, 'rb') as f:
                    raw_bytes = f.read()
            else:
                raw_bytes = bytes(photo_data if isinstance(photo_data, (bytes, bytearray)) else bytes(photo_data))

            pil_img = Image.open(io.BytesIO(raw_bytes))
            from PIL import ImageOps as _ImageOps
            pil_img = _ImageOps.exif_transpose(pil_img)
            if pil_img.mode not in ("RGB", "L"):
                pil_img = pil_img.convert("RGB")
            np_img = np.array(pil_img)

            # D√©tection robuste
            face_locations = self._detect_faces_multipass(np_img)
            if not face_locations:
                return []
            face_encodings = face_recognition.face_encodings(np_img, face_locations)
            if not face_encodings:
                return []

            # Encodages des utilisateurs de l'√©v√©nement (avec cache)
            user_encodings = self.get_user_encodings_for_event(db, event_id)
            if not user_encodings:
                return []
            user_ids = list(user_encodings.keys())
            user_matrix = np.array([user_encodings[uid] for uid in user_ids])

            # Calcul vectoris√© des distances et d√©duplication par utilisateur
            best_by_user: Dict[int, int] = {}
            for enc in face_encodings:
                try:
                    dists = face_recognition.face_distance(user_matrix, enc)
                except Exception:
                    dists = np.array([face_recognition.face_distance([u], enc)[0] for u in user_matrix])
                for idx, dist in enumerate(dists):
                    if dist <= self.tolerance:
                        uid = user_ids[idx]
                        score = max(0, int((1 - float(dist)) * 100))
                        if (uid not in best_by_user) or (score > best_by_user[uid]):
                            best_by_user[uid] = score

            matches = [{
                'user_id': uid,
                'confidence_score': score,
                'distance': 1 - (score / 100.0)
            } for uid, score in best_by_user.items()]

            return matches
            
        except Exception as e:
            print(f"Erreur lors du traitement de la photo: {e}")
            return []

    def _get_content_type(self, filename: str) -> str:
        """D√©termine le type MIME d'un fichier bas√© sur son extension"""
        extension = os.path.splitext(filename)[1].lower()
        content_types = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp'
        }
        return content_types.get(extension, 'image/jpeg')

    def get_user_photos_with_face(self, user_id: int, db: Session) -> List[Photo]:
        """R√©cup√®re toutes les photos o√π un utilisateur appara√Æt"""
        from sqlalchemy import and_
        
        # R√©cup√©rer les photos via les correspondances de visages
        photos = db.query(Photo).join(FaceMatch).filter(
            and_(
                FaceMatch.user_id == user_id,
                FaceMatch.photo_id == Photo.id
            )
        ).all()
        
        return photos

    def get_all_photos_for_user(self, user_id: int, db: Session) -> List[Photo]:
        """R√©cup√®re toutes les photos disponibles pour un utilisateur"""
        return db.query(Photo).filter(Photo.photo_type == "uploaded").all()

    def match_user_selfie_with_photos(self, user: User, db: Session):
        """
        Apr√®s ajout ou modification d'un selfie, parcourt toutes les photos de l'√©v√©nement de l'utilisateur,
        compare le visage du selfie √† chaque visage d√©tect√© sur chaque photo,
        et ajoute les correspondances dans FaceMatch si un match est trouv√©.
        """
        # Charger l'encodage du nouveau selfie
        user_encoding = self.load_user_encoding(user)
        if user_encoding is None:
            return 0

        # Trouver l'√©v√©nement de l'utilisateur
        from models import UserEvent
        user_event = db.query(UserEvent).filter(UserEvent.user_id == user.id).first()
        if not user_event:
            return 0

        # Supprimer les anciens FaceMatch pour cet utilisateur sur cet √©v√©nement
        from models import Photo
        photo_ids = [p.id for p in db.query(Photo).filter(Photo.event_id == user_event.event_id).all()]
        db.query(FaceMatch).filter(FaceMatch.user_id == user.id, FaceMatch.photo_id.in_(photo_ids)).delete(synchronize_session=False)
        db.commit()

        # Parcourir toutes les photos de l'√©v√©nement
        photos = db.query(Photo).filter(Photo.event_id == user_event.event_id).all()
        match_count = 0
        for photo in photos:
            try:
                image = None
                if photo.photo_data:
                    image_data = io.BytesIO(photo.photo_data)
                    image = face_recognition.load_image_file(image_data)
                elif getattr(photo, "file_path", None) and os.path.exists(photo.file_path):
                    image = face_recognition.load_image_file(photo.file_path)
                if image is None:
                    continue
                face_locations = face_recognition.face_locations(image)
                face_encodings = face_recognition.face_encodings(image, face_locations)
                for face_encoding in face_encodings:
                    distance = face_recognition.face_distance([user_encoding], face_encoding)[0]
                    confidence_score = max(0, int((1 - distance) * 100))
                    if distance <= self.tolerance:
                        face_match = FaceMatch(
                            photo_id=photo.id,
                            user_id=user.id,
                            confidence_score=confidence_score
                        )
                        db.add(face_match)
                        match_count += 1
            except Exception as e:
                print(f"Erreur lors du matching selfie sur photo {photo.id}: {e}")
        db.commit()
        return match_count

    def match_user_selfie_with_photos_event(self, user: User, event_id: int, db: Session):
        """
        Apr√®s ajout ou modification d'un selfie, parcourt toutes les photos d'un √©v√©nement,
        compare le visage du selfie √† chaque visage d√©tect√© sur chaque photo,
        et ajoute les correspondances dans FaceMatch si un match est trouv√©.
        """
        user_encoding = self.load_user_encoding(user)
        if user_encoding is None:
            return 0
        # Supprimer les anciens FaceMatch pour cet utilisateur sur cet √©v√©nement
        from models import Photo
        photo_ids = [p.id for p in db.query(Photo).filter(Photo.event_id == event_id).all()]
        db.query(FaceMatch).filter(FaceMatch.user_id == user.id, FaceMatch.photo_id.in_(photo_ids)).delete(synchronize_session=False)
        db.commit()
        # Parcourir toutes les photos de l'√©v√©nement
        photos = db.query(Photo).filter(Photo.event_id == event_id).all()
        match_count = 0
        for photo in photos:
            try:
                image = None
                if photo.photo_data:
                    image_data = io.BytesIO(photo.photo_data)
                    image = face_recognition.load_image_file(image_data)
                elif getattr(photo, "file_path", None) and os.path.exists(photo.file_path):
                    image = face_recognition.load_image_file(photo.file_path)
                if image is None:
                    continue
                face_locations = face_recognition.face_locations(image)
                face_encodings = face_recognition.face_encodings(image, face_locations)
                for face_encoding in face_encodings:
                    distance = face_recognition.face_distance([user_encoding], face_encoding)[0]
                    confidence_score = max(0, int((1 - distance) * 100))
                    if distance <= self.tolerance:
                        face_match = FaceMatch(
                            photo_id=photo.id,
                            user_id=user.id,
                            confidence_score=confidence_score
                        )
                        db.add(face_match)
                        match_count += 1
            except Exception as e:
                print(f"Erreur lors du matching selfie sur photo {photo.id}: {e}")
        db.commit()
        return match_count
