# üöÄ Fix Performance : Multi-Workers pour 30+ Utilisateurs Simultan√©s

## üìä Diagnostic du Probl√®me

### Sympt√¥mes Observ√©s
- ‚úó **30 utilisateurs** simultan√©s causaient des lags et bugs
- ‚úó **CPU √† 40%** maximum alors qu'il y a 2 vCPU disponibles
- ‚úó Ressources sous-utilis√©es malgr√© la charge

### Cause Racine Identifi√©e üéØ
**1 seul worker Uvicorn** ‚Üí Toutes les requ√™tes trait√©es s√©quentiellement !

```bash
# AVANT (probl√©matique)
exec uvicorn main:app --host 0.0.0.0 --port ${PORT:-10000} --log-level info
# ‚ö†Ô∏è 1 seul processus = 1 seul c≈ìur utilis√© = 50% CPU max sur 2 vCPU
```

**R√©sultat** : Les requ√™tes s'accumulent dans la queue au lieu d'√™tre trait√©es en parall√®le.

---

## ‚úÖ Solutions Mises en Place

### 1. üîß Multi-Workers avec Gunicorn

**Fichier modifi√©** : `start.sh`

```bash
# APR√àS (optimis√©)
WORKERS=${GUNICORN_WORKERS:-5}  # (2 x CPU) + 1 = 5 workers

exec gunicorn main:app \
  --workers ${WORKERS} \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:${PORT:-10000} \
  --timeout 120 \
  --keep-alive 5 \
  --max-requests 1000 \
  --max-requests-jitter 100 \
  --log-level info
```

**B√©n√©fices** :
- ‚úì **5 processus** travaillent en parall√®le
- ‚úì **Utilisation CPU** : 70-90% sous charge (vs 40% avant)
- ‚úì **30+ utilisateurs** support√©s simultan√©ment
- ‚úì **Graceful restarts** : les workers se recyclent automatiquement

---

### 2. ‚ö° Augmentation Concurrence AWS Rekognition

**Fichier modifi√©** : `service.json` + `ENV_AWS_PRODUCTION.txt`

```bash
# AVANT
AWS_CONCURRENT_REQUESTS=10  # Trop bas pour 5 workers

# APR√àS
AWS_CONCURRENT_REQUESTS=20  # 4 requ√™tes/worker en moyenne
```

**Impact** : Les requ√™tes de reconnaissance faciale ne bloquent plus les autres workers.

---

### 3. üóÑÔ∏è Pool de Connexions DB Augment√©

**Fichier modifi√©** : `service.json`

```bash
# AVANT
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=50  # Total: 70 connexions

# APR√àS
DB_POOL_SIZE=30
DB_MAX_OVERFLOW=70  # Total: 100 connexions
```

**Formule recommand√©e** : 
- Pool size = workers √ó 6 connexions/worker
- Overflow = marge pour les pics de charge

---

### 4. üì¶ Ajout de Gunicorn

**Fichier modifi√©** : `requirements.txt`

```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
gunicorn==21.2.0  # ‚Üê NOUVEAU
```

---

## üìà R√©sultats Attendus

| M√©trique | Avant | Apr√®s |
|----------|-------|-------|
| **Workers** | 1 üò± | 5 ‚úÖ |
| **Requ√™tes parall√®les** | 1 | 5-10+ |
| **AWS concurrent** | 10 | 20 |
| **DB connexions** | 70 max | 100 max |
| **Utilisation CPU** | 40% | 80-90% ‚úÖ |
| **Utilisateurs fluides** | ~5 | **30+** ‚úÖ |
| **Temps de r√©ponse** | Variable | Stable |

---

## üöÄ D√©ploiement

### √âtape 1 : Mise √† Jour des D√©pendances

```bash
cd face_recognition/app
pip install -r requirements.txt
```

### √âtape 2 : V√©rifier la Configuration

V√©rifiez que `service.json` contient les nouvelles variables :

```json
"RuntimeEnvironmentVariables": {
  "GUNICORN_WORKERS": "5",
  "AWS_CONCURRENT_REQUESTS": "20",
  "DB_POOL_SIZE": "30",
  "DB_MAX_OVERFLOW": "70"
}
```

### √âtape 3 : D√©ployer sur AWS

```bash
# Build et push de la nouvelle image Docker
docker build -t findme-prod:v8 .
docker tag findme-prod:v8 801541932532.dkr.ecr.eu-west-3.amazonaws.com/findme-prod:v8
docker push 801541932532.dkr.ecr.eu-west-3.amazonaws.com/findme-prod:v8

# Mise √† jour du service AWS App Runner
aws apprunner update-service \
  --cli-input-json file://service.json \
  --region eu-west-3
```

### √âtape 4 : V√©rification Post-D√©ploiement

#### A. V√©rifier que les workers tournent

Connectez-vous √† votre instance AWS (logs ou SSH) et ex√©cutez :

```bash
ps aux | grep gunicorn
```

**R√©sultat attendu** : 6 processus
```
gunicorn: master [main:app]        # 1 master
gunicorn: worker [main:app]        # worker 1
gunicorn: worker [main:app]        # worker 2
gunicorn: worker [main:app]        # worker 3
gunicorn: worker [main:app]        # worker 4
gunicorn: worker [main:app]        # worker 5
```

#### B. V√©rifier les logs de d√©marrage

Dans AWS CloudWatch ou logs App Runner, cherchez :

```
üåê D√©marrage du serveur avec Gunicorn...
  - Workers: 5
  - Port: 10000
  - Timeout: 120s
[INFO] Booting worker with pid: ...
[INFO] Booting worker with pid: ...
[INFO] Booting worker with pid: ...
[INFO] Booting worker with pid: ...
[INFO] Booting worker with pid: ...
```

#### C. Test de Charge

Utilisez un outil comme `ab` (Apache Bench) ou `wrk` :

```bash
# Test avec 30 connexions simultan√©es
ab -n 1000 -c 30 https://votre-app.amazonaws.com/

# R√©sultat attendu:
# - Requests per second: > 100
# - Time per request: < 300ms (moyenne)
# - Failed requests: 0
```

---

## üéØ Configuration Adaptative

### Pour Plus de Charge (50+ utilisateurs)

**Option 1** : Augmenter les workers (si vous passez √† 4 vCPU)

```bash
# Pour 4 vCPU: (2 √ó 4) + 1 = 9 workers
GUNICORN_WORKERS=9
AWS_CONCURRENT_REQUESTS=30
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=100
```

**Option 2** : Auto-scaling AWS App Runner

Votre configuration actuelle utilise d√©j√† l'auto-scaling :
```json
"AutoScalingConfigurationArn": "arn:aws:apprunner:eu-west-3:801541932532:autoscalingconfiguration/findme-autoscaling-v2/1/..."
```

‚Üí AWS cr√©era automatiquement des instances suppl√©mentaires si la charge d√©passe les capacit√©s.

---

### Pour √âconomiser (Environnement de Test)

```bash
# Configuration minimale
GUNICORN_WORKERS=2
AWS_CONCURRENT_REQUESTS=5
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
```

---

## üîç Monitoring et Diagnostic

### M√©triques √† Surveiller

#### 1. Utilisation CPU (CloudWatch)

**Attendu** : 70-90% sous charge normale

Si < 50% : Workers insuffisamment utilis√©s
Si > 95% : Augmenter les ressources ou l'auto-scaling

#### 2. Connexions Base de Donn√©es

**Attendu** : 15-40 connexions actives avec 30 utilisateurs

Commande PostgreSQL :
```sql
SELECT count(*) FROM pg_stat_activity WHERE state = 'active';
```

Si > 80 connexions : Augmenter `DB_MAX_OVERFLOW`

#### 3. Temps de R√©ponse AWS Rekognition

**Attendu** : 200-500ms par requ√™te

Dans les logs, cherchez :
```
[aws_face_recognizer] IndexFaces: 245ms
[aws_face_recognizer] SearchFaces: 312ms
```

Si > 1000ms : Possible throttling AWS ‚Üí V√©rifier les quotas

#### 4. Queue Gunicorn

**Attendu** : < 10 requ√™tes en attente

Si > 50 : Augmenter `GUNICORN_WORKERS` ou activer l'auto-scaling

---

## ‚ö†Ô∏è Points d'Attention

### 1. Instance Configuration

**IMPORTANT** : Votre `service.json` indique actuellement :
```json
"InstanceConfiguration": { "Cpu": "1 vCPU", "Memory": "4 GB" }
```

**Recommandation** : Si vous avez vraiment 2 vCPU (comme mentionn√©), mettez √† jour :
```json
"InstanceConfiguration": { "Cpu": "2 vCPU", "Memory": "4 GB" }
```

Sinon, ajustez `GUNICORN_WORKERS` √† **3** pour 1 vCPU : `(2 √ó 1) + 1 = 3`

### 2. Quotas AWS Rekognition

V√©rifiez vos limites dans la console AWS :
- **IndexFaces** : 50 TPS (transactions par seconde) par d√©faut
- **SearchFaces** : 50 TPS par d√©faut

Avec 20 requ√™tes concurrentes, vous pouvez atteindre ces limites.

**Solution** : Demander une augmentation de quota via AWS Support si n√©cessaire.

### 3. Co√ªts AWS

Plus de workers = plus de requ√™tes parall√®les = co√ªts AWS Rekognition potentiellement plus √©lev√©s.

**Monitoring** : Activez AWS Cost Explorer et surveillez :
- Nombre d'appels Rekognition
- Co√ªt par jour/mois

---

## üêõ Troubleshooting

### Probl√®me : Workers ne d√©marrent pas

**Sympt√¥me** : 1 seul processus gunicorn visible

**Causes possibles** :
1. Gunicorn pas install√© ‚Üí V√©rifier `pip list | grep gunicorn`
2. Variable `GUNICORN_WORKERS` pas d√©finie ‚Üí V√©rifier les env vars
3. Erreur dans `start.sh` ‚Üí V√©rifier les logs de d√©marrage

**Solution** :
```bash
# Test manuel
gunicorn main:app --workers 5 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:10000
```

---

### Probl√®me : Timeouts fr√©quents

**Sympt√¥me** : Erreurs 504 Gateway Timeout

**Causes possibles** :
1. Workers surcharg√©s ‚Üí Augmenter `GUNICORN_WORKERS`
2. Timeout trop court ‚Üí Augmenter `--timeout` dans start.sh
3. Requ√™tes AWS lentes ‚Üí V√©rifier throttling

**Solution** :
```bash
# Dans start.sh, augmenter le timeout
--timeout 180  # au lieu de 120
```

---

### Probl√®me : Erreurs de connexion DB

**Sympt√¥me** : `psycopg2.OperationalError: connection pool exhausted`

**Cause** : Trop de connexions simultan√©es

**Solution** :
```bash
DB_POOL_SIZE=40
DB_MAX_OVERFLOW=100
```

---

## üìö R√©f√©rences

### Documentation Gunicorn
- Settings : https://docs.gunicorn.org/en/stable/settings.html
- Workers : https://docs.gunicorn.org/en/stable/design.html#how-many-workers

### Formule Workers
```
workers = (2 √ó CPU) + 1
```

Source : https://docs.gunicorn.org/en/stable/design.html#how-many-workers

### AWS Rekognition Quotas
- https://docs.aws.amazon.com/rekognition/latest/dg/limits.html

---

## ‚úÖ Checklist Finale

Avant de consid√©rer le d√©ploiement termin√© :

- [ ] `gunicorn` ajout√© √† `requirements.txt` ‚úì
- [ ] `start.sh` modifi√© avec multi-workers ‚úì
- [ ] Variables d'environnement mises √† jour dans `service.json` ‚úì
- [ ] Configuration CPU/Memory v√©rifi√©e dans AWS
- [ ] Image Docker build√©e et push√©e
- [ ] Service AWS App Runner mis √† jour
- [ ] Logs de d√©marrage v√©rifi√©s (6 processus gunicorn)
- [ ] Test de charge effectu√© (30+ utilisateurs)
- [ ] Monitoring CPU activ√© (70-90% attendu)
- [ ] Quotas AWS Rekognition v√©rifi√©s
- [ ] Documentation √©quipe partag√©e

---

## üéâ R√©sum√©

**Le probl√®me** : 1 worker = 1 c≈ìur = 50% CPU max = lags avec 30 users

**La solution** : 5 workers = parall√©lisation = 90% CPU = 30+ users fluides

**Impact estim√©** :
- **6x plus de capacit√©** (1 ‚Üí 5 workers)
- **2x plus de requ√™tes AWS** (10 ‚Üí 20 concurrent)
- **1.4x plus de connexions DB** (70 ‚Üí 100 max)
- **= Support de 30+ utilisateurs simultan√©s sans lag** ‚úÖ

---

*Documentation cr√©√©e le : 2025-01-05*
*Version : 1.0*

